{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"prefect-ray","text":""},{"location":"#welcome","title":"Welcome!","text":"<p>Prefect integrations with the Ray execution framework, a flexible distributed computing framework for Python.</p> <p>Provides a <code>RayTaskRunner</code> that enables flows to run tasks requiring parallel execution using Ray.</p>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#python-setup","title":"Python setup","text":"<p>Requires an installation of Python 3.7+.</p> <p>We recommend using a Python virtual environment manager such as pipenv, conda, or virtualenv.</p> <p>These tasks are designed to work with Prefect 2.0. For more information about how to use Prefect, please refer to the Prefect documentation.</p>"},{"location":"#installation","title":"Installation","text":"<p>Install <code>prefect-ray</code> with <code>pip</code>:</p> <pre><code>pip install prefect-ray\n</code></pre> <p>Users running Apple Silicon (such as M1 macs) will need to additionally run: <pre><code>pip uninstall grpcio\nconda install grpcio\n</code></pre> Click here for more details.</p>"},{"location":"#running-tasks-on-ray","title":"Running tasks on Ray","text":"<p>The <code>RayTaskRunner</code> is a Prefect task runner that submits tasks to Ray for parallel execution. </p> <p>By default, a temporary Ray instance is created for the duration of the flow run.</p> <p>For example, this flow counts to 3 in parallel.</p> <pre><code>import time\n\nfrom prefect import flow, task\nfrom prefect_ray import RayTaskRunner\n\n@task\ndef shout(number):\n    time.sleep(0.5)\n    print(f\"#{number}\")\n\n@flow(task_runner=RayTaskRunner)\ndef count_to(highest_number):\n    for number in range(highest_number):\n        shout.submit(number)\n\nif __name__ == \"__main__\":\n    count_to(10)\n\n# outputs\n#3\n#7\n#2\n#6\n#4\n#0\n#1\n#5\n#8\n#9\n</code></pre> <p>If you already have a Ray instance running, you can provide the connection URL via an <code>address</code> argument.</p> <p>To configure your flow to use the <code>RayTaskRunner</code>:</p> <ol> <li>Make sure the <code>prefect-ray</code> collection is installed as described earlier: <code>pip install prefect-ray</code>.</li> <li>In your flow code, import <code>RayTaskRunner</code> from <code>prefect_ray.task_runners</code>.</li> <li>Assign it as the task runner when the flow is defined using the <code>task_runner=RayTaskRunner</code> argument.</li> </ol> <p>For example, this flow uses the <code>RayTaskRunner</code> with a local, temporary Ray instance created by Prefect at flow run time.</p> <pre><code>from prefect import flow\nfrom prefect_ray.task_runners import RayTaskRunner\n\n@flow(task_runner=RayTaskRunner())\ndef my_flow():\n    ... \n</code></pre> <p>This flow uses the <code>RayTaskRunner</code> configured to access an existing Ray instance at <code>ray://192.0.2.255:8786</code>.</p> <pre><code>from prefect import flow\nfrom prefect_ray.task_runners import RayTaskRunner\n\n@flow(task_runner=RayTaskRunner(address=\"ray://192.0.2.255:8786\"))\ndef my_flow():\n    ... \n</code></pre> <p><code>RayTaskRunner</code> accepts the following optional parameters:</p> Parameter Description address Address of a currently running Ray instance, starting with the ray:// URI. init_kwargs Additional kwargs to use when calling <code>ray.init</code>. <p>Note that Ray Client uses the ray:// URI to indicate the address of a Ray instance. If you don't provide the <code>address</code> of a Ray instance, Prefect creates a temporary instance automatically.</p> <p>Ray environment limitations</p> <p>While we're excited about adding support for parallel task execution via Ray to Prefect, there are some inherent limitations with Ray you should be aware of:</p> <p>Ray currently does not support Python 3.10.</p> <p>Ray support for non-x86/64 architectures such as ARM/M1 processors with installation from <code>pip</code> alone and will be skipped during installation of Prefect. It is possible to manually install the blocking component with <code>conda</code>. See the Ray documentation for instructions.</p> <p>See the Ray installation documentation for further compatibility information.</p>"},{"location":"#running-tasks-on-a-ray-remote-cluster","title":"Running tasks on a Ray remote cluster","text":"<p>When using the <code>RayTaskRunner</code> with a remote Ray cluster, you may run into issues that are not seen when using a local Ray instance. To resolve these issues, we recommend taking the following steps when working with a remote Ray cluster:</p> <ol> <li>By default, Prefect will not persist any data to the filesystem of the remote ray worker. However, if you want to take advantage of Prefect's caching ability, you will need to configure a remote result storage to persist results across task runs. </li> </ol> <p>We recommend using the Prefect UI to configure a storage block to use for remote results storage.</p> <p>Here's an example of a flow that uses caching and remote result storage: <pre><code>from typing import List\n\nfrom prefect import flow, get_run_logger, task\nfrom prefect.filesystems import S3\nfrom prefect.tasks import task_input_hash\nfrom prefect_ray.task_runners import RayTaskRunner\n\n\n# The result of this task will be cached in the configured result storage\n@task(cache_key_fn=task_input_hash)\ndef say_hello(name: str) -&gt; None:\n    logger = get_run_logger()\n    # This log statement will print only on the first run. Subsequent runs will be cached.\n    logger.info(f\"hello {name}!\")\n    return name\n\n\n@flow(\n    task_runner=RayTaskRunner(\n        address=\"ray://&lt;instance_public_ip_address&gt;:10001\",\n    ),\n    # Using an S3 block that has already been created via the Prefect UI\n    result_storage=\"s3/my-result-storage\",\n)\ndef greetings(names: List[str]) -&gt; None:\n    for name in names:\n        say_hello.submit(name)\n\n\nif __name__ == \"__main__\":\n    greetings([\"arthur\", \"trillian\", \"ford\", \"marvin\"])\n</code></pre></p> <ol> <li> <p>If you get an error stating that the module 'prefect' cannot be found, ensure <code>prefect</code> is installed on the remote cluster, with: <pre><code>pip install prefect\n</code></pre></p> </li> <li> <p>If you get an error with a message similar to \"File system created with scheme 's3' could not be created\", ensure the required Python modules are installed on both local and remote machines. The required prerequisite modules can be found in the Prefect documentation. For example, if using S3 for the remote storage: <pre><code>pip install s3fs\n</code></pre></p> </li> <li> <p>If you are seeing timeout or other connection errors, double check the address provided to the <code>RayTaskRunner</code>. The address should look similar to: <code>address='ray://&lt;head_node_ip_address&gt;:10001'</code>: <pre><code>RayTaskRunner(address=\"ray://1.23.199.255:10001\")\n</code></pre></p> </li> </ol>"},{"location":"#specifying-remote-options","title":"Specifying remote options","text":"<p>The <code>remote_options</code> context can be used to control the task\u2019s remote options.</p> <p>For example, we can set the number of CPUs and GPUs to use for the <code>process</code> task:</p> <pre><code>from prefect import flow, task\nfrom prefect_ray.task_runners import RayTaskRunner\nfrom prefect_ray.context import remote_options\n\n@task\ndef process(x):\n    return x + 1\n\n\n@flow(task_runner=RayTaskRunner())\ndef my_flow():\n    # equivalent to setting @ray.remote(num_cpus=4, num_gpus=2)\n    with remote_options(num_cpus=4, num_gpus=2):\n        process.submit(42)\n</code></pre>"},{"location":"#resources","title":"Resources","text":"<p>If you encounter and bugs while using <code>prefect-ray</code>, feel free to open an issue in the prefect-ray repository.</p> <p>If you have any questions or issues while using <code>prefect-ray</code>, you can find help in either the Prefect Discourse forum or the Prefect Slack community.</p> <p>Feel free to \u2b50\ufe0f or watch <code>prefect-ray</code> for updates too!</p>"},{"location":"#development","title":"Development","text":"<p>If you'd like to install a version of <code>prefect-ray</code> for development, clone the repository and perform an editable install with <code>pip</code>:</p> <pre><code>git clone https://github.com/PrefectHQ/prefect-ray.git\n\ncd prefect-ray/\n\npip install -e \".[dev]\"\n\n# Install linting pre-commit hooks\npre-commit install\n</code></pre>"},{"location":"task_runners/","title":"Task Runners","text":""},{"location":"task_runners/#prefect_ray.task_runners","title":"<code>prefect_ray.task_runners</code>","text":"<p>Interface and implementations of the Ray Task Runner. Task Runners in Prefect are responsible for managing the execution of Prefect task runs. Generally speaking, users are not expected to interact with task runners outside of configuring and initializing them for a flow.</p> Example <pre><code>import time\n\nfrom prefect import flow, task\n\n@task\ndef shout(number):\n    time.sleep(0.5)\n    print(f\"#{number}\")\n\n@flow\ndef count_to(highest_number):\n    for number in range(highest_number):\n        shout.submit(number)\n\nif __name__ == \"__main__\":\n    count_to(10)\n\n# outputs\n#0\n#1\n#2\n#3\n#4\n#5\n#6\n#7\n#8\n#9\n</code></pre> <p>Switching to a <code>RayTaskRunner</code>: <pre><code>import time\n\nfrom prefect import flow, task\nfrom prefect_ray import RayTaskRunner\n\n@task\ndef shout(number):\n    time.sleep(0.5)\n    print(f\"#{number}\")\n\n@flow(task_runner=RayTaskRunner)\ndef count_to(highest_number):\n    for number in range(highest_number):\n        shout.submit(number)\n\nif __name__ == \"__main__\":\n    count_to(10)\n\n# outputs\n#3\n#7\n#2\n#6\n#4\n#0\n#1\n#5\n#8\n#9\n</code></pre></p>"},{"location":"task_runners/#prefect_ray.task_runners-classes","title":"Classes","text":""},{"location":"task_runners/#prefect_ray.task_runners.RayTaskRunner","title":"<code>RayTaskRunner</code>","text":"<p>         Bases: <code>BaseTaskRunner</code></p> <p>A parallel task_runner that submits tasks to <code>ray</code>. By default, a temporary Ray cluster is created for the duration of the flow run. Alternatively, if you already have a <code>ray</code> instance running, you can provide the connection URL via the <code>address</code> kwarg.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <code>string</code> <p>Address of a currently running <code>ray</code> instance; if one is not provided, a temporary instance will be created.</p> <code>None</code> <code>init_kwargs</code> <code>dict</code> <p>Additional kwargs to use when calling <code>ray.init</code>.</p> <code>None</code> <p>Examples:</p> <p>Using a temporary local ray cluster: <pre><code>from prefect import flow\nfrom prefect_ray.task_runners import RayTaskRunner\n\n@flow(task_runner=RayTaskRunner())\ndef my_flow():\n    ...\n</code></pre> Connecting to an existing ray instance: <pre><code>RayTaskRunner(address=\"ray://192.0.2.255:8786\")\n</code></pre></p> Source code in <code>prefect_ray/task_runners.py</code> <pre><code>class RayTaskRunner(BaseTaskRunner):\n\"\"\"\n    A parallel task_runner that submits tasks to `ray`.\n    By default, a temporary Ray cluster is created for the duration of the flow run.\n    Alternatively, if you already have a `ray` instance running, you can provide\n    the connection URL via the `address` kwarg.\n    Args:\n        address (string, optional): Address of a currently running `ray` instance; if\n            one is not provided, a temporary instance will be created.\n        init_kwargs (dict, optional): Additional kwargs to use when calling `ray.init`.\n    Examples:\n        Using a temporary local ray cluster:\n        ```python\n        from prefect import flow\n        from prefect_ray.task_runners import RayTaskRunner\n\n        @flow(task_runner=RayTaskRunner())\n        def my_flow():\n            ...\n        ```\n        Connecting to an existing ray instance:\n        ```python\n        RayTaskRunner(address=\"ray://192.0.2.255:8786\")\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        address: str = None,\n        init_kwargs: dict = None,\n    ):\n        # Store settings\n        self.address = address\n        self.init_kwargs = init_kwargs.copy() if init_kwargs else {}\n\n        self.init_kwargs.setdefault(\"namespace\", \"prefect\")\n        self.init_kwargs\n\n        # Runtime attributes\n        self._ray_refs: Dict[str, \"ray.ObjectRef\"] = {}\n\n        super().__init__()\n\n    @property\n    def concurrency_type(self) -&gt; TaskConcurrencyType:\n        return TaskConcurrencyType.PARALLEL\n\n    async def submit(\n        self,\n        key: UUID,\n        call: Callable[..., Awaitable[State[R]]],\n    ) -&gt; None:\n        if not self._started:\n            raise RuntimeError(\n                \"The task runner must be started before submitting work.\"\n            )\n\n        call_kwargs = self._optimize_futures(call.keywords)\n\n        remote_options = RemoteOptionsContext.get().current_remote_options\n        # Ray does not support the submission of async functions and we must create a\n        # sync entrypoint\n        if remote_options:\n            ray_decorator = ray.remote(**remote_options)\n        else:\n            ray_decorator = ray.remote\n        self._ray_refs[key] = ray_decorator(sync_compatible(call.func)).remote(\n            **call_kwargs\n        )\n\n    def _optimize_futures(self, expr):\n\"\"\"\n        Exchange PrefectFutures for ray-compatible futures\n        \"\"\"\n\n        def visit_fn(expr):\n\"\"\"\n            Resolves ray futures when used as dependencies\n            \"\"\"\n            if isinstance(expr, PrefectFuture):\n                ray_future = self._ray_refs.get(expr.key)\n                if ray_future is not None:\n                    return ray.get(ray_future)\n            # Fallback to return the expression unaltered\n            return expr\n\n        return visit_collection(expr, visit_fn=visit_fn, return_data=True)\n\n    async def wait(self, key: UUID, timeout: float = None) -&gt; Optional[State]:\n        ref = self._get_ray_ref(key)\n\n        result = None\n\n        with anyio.move_on_after(timeout):\n            # We await the reference directly instead of using `ray.get` so we can\n            # avoid blocking the event loop\n            try:\n                result = await ref\n            except RayTaskError as exc:\n                # unwrap the original exception that caused task failure, except for\n                # KeyboardInterrupt, which unwraps as TaskCancelledError\n                result = await exception_to_crashed_state(exc.cause)\n            except BaseException as exc:\n                result = await exception_to_crashed_state(exc)\n\n        return result\n\n    async def _start(self, exit_stack: AsyncExitStack):\n\"\"\"\n        Start the task runner and prep for context exit.\n\n        - Creates a cluster if an external address is not set.\n        - Creates a client to connect to the cluster.\n        - Pushes a call to wait for all running futures to complete on exit.\n        \"\"\"\n        if self.address and self.address != \"auto\":\n            self.logger.info(\n                f\"Connecting to an existing Ray instance at {self.address}\"\n            )\n            init_args = (self.address,)\n        elif ray.is_initialized():\n            self.logger.info(\n                \"Local Ray instance is already initialized. \"\n                \"Using existing local instance.\"\n            )\n            return\n        else:\n            self.logger.info(\"Creating a local Ray instance\")\n            init_args = ()\n\n        context = ray.init(*init_args, **self.init_kwargs)\n        dashboard_url = getattr(context, \"dashboard_url\", None)\n        exit_stack.push(context)\n\n        # Display some information about the cluster\n        nodes = ray.nodes()\n        living_nodes = [node for node in nodes if node.get(\"alive\")]\n        self.logger.info(f\"Using Ray cluster with {len(living_nodes)} nodes.\")\n\n        if dashboard_url:\n            self.logger.info(\n                f\"The Ray UI is available at {dashboard_url}\",\n            )\n\n    async def _shutdown_ray(self):\n\"\"\"\n        Shuts down the cluster.\n        \"\"\"\n        self.logger.debug(\"Shutting down Ray cluster...\")\n        ray.shutdown()\n\n    def _get_ray_ref(self, key: UUID) -&gt; \"ray.ObjectRef\":\n\"\"\"\n        Retrieve the ray object reference corresponding to a prefect future.\n        \"\"\"\n        return self._ray_refs[key]\n</code></pre>"}]}